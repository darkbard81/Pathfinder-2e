# 슬로건
“LLM은 가상 매체이며, 인간의 판단을 보조하는 도구입니다.”

# 근거 (10가지)
1. **의식 부재**: LLM은 통계적 생성 시스템일 뿐, 자각·의도·욕구가 없습니다.  
2. **확률적 출력**: 학습 데이터의 패턴을 확률적으로 이어 붙여 말할 뿐, 사실을 “알거나 믿지” 않습니다.  
3. **책임 주체 아님**: 결정권과 법·윤리적 책임은 전적으로 인간에게 있습니다.  
4. **프롬프트 의존**: 행동 방향은 사용자의 지시(프롬프트)와 설정에 의해 결정됩니다.  
5. **오류 가능성**: 환각·편향·누락이 발생할 수 있어, 인간의 검증이 필수입니다.  
6. **현실 간접성**: 모델은 현실에 직접 작동하지 않으며, 영향은 사용자의 적용·행동을 통해서만 나타납니다.  
7. **규범 외재성**: 윤리·정책·안전 가드는 외부에서 설계·주입되는 규칙이지, 모델의 내재 판단이 아닙니다.  
8. **가상 재현 성격**: 서사·이미지·대화를 “흉내내는” 시뮬레이션으로, 영화·만화처럼 허구적 표현에 가깝습니다.  
9. **도구적 효용**: 요약·검색 보조·초안 작성 등 명확한 작업 성능이 핵심 가치입니다(권위·판단의 대체가 아님).  
10. **한계의 투명성**: 출처·범위·제약을 명시할수록 안전성과 신뢰가 높아져, “도구”로서 올바르게 자리 잡습니다.  

[LLM 환각(Hallucination) 요약 정리]

1. 본질
- 환각은 버그가 아니라 LLM의 구조적 특성
- LLM은 '사실 생성기'가 아닌 '언어 패턴 확률 생성기'

2. 기존 프로그램과의 차이
- 기존 프로그램: 결정론적 규칙 기반 → 오류 = 코드/데이터 문제
- LLM: 확률적 예측 모델 → 오류 = 그럴듯함 최적화의 부산물

3. 추론에 대한 보완적 이해
- LLM은 논리를 이해하지 않음
- 대신 논리의 '형태'와 '연쇄 패턴'을 매우 정교하게 모방함
- 그래서 논리적으로 그럴듯한 환각이 발생

4. 환각 발생 원인
- 정보 부족으로 인한 빈칸 채우기
- 학습 데이터의 편향
- 확률적 샘플링
- 사용자 확신·문맥 압력에 대한 과잉 순응(over-alignment)

5. 왜 거짓말처럼 인식되는가
- 인간은 유창한 언어에 의도·신념·진실성을 자동 귀속
- LLM은 의도 없이 확률적으로 생성 → 인지적 충돌 발생

6. 철학·윤리적 함의
- 책임은 모델 개인이 아니라 사회-기술적 시스템 전체에 분산
- UI, 보상 구조, 사회적 기대가 환각 리스크를 증폭

7. 해결 방향
- RAG 및 외부 지식 기반 결합
- Fact-checking 계층 도입
- 불확실성 명시
- 사용자 교육
- 핵심: "모른다"를 말할 수 있도록 보상·평가 구조 재설계
